{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuAgV5Sdcqn5q8pMwOqdwv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aeshwin10/Basic-ML-Models/blob/main/PyTorch_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDlowFR9xw4J"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "8TOXIzvW1SAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensors - very special datatype of PyTorch. They also carry a lot of underlying things.\n",
        "#We wrap our vectors inside a tensor instead of something like a python list, to get those underlying things.\n",
        "torch.ones(5,5)\n",
        "torch.ones(5,5,5) #each parameter is a dimension\n",
        "torch.tensor((1,2,3)) #tensor() accepts a python list or tuple and converts it into a tensor - here, it is not a dimension.\n",
        "torch.tensor([1,2,3]) + torch.ones(3,3) #adding two tensors #Also learn about broadcasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ1wtCkByHLr",
        "outputId": "b177d085-8886-46af-9343-4dbf7bf423c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3., 4.],\n",
              "        [2., 3., 4.],\n",
              "        [2., 3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modules"
      ],
      "metadata": {
        "id": "lin7H6FH1YiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modules are building block\n",
        "\n",
        "import torch.nn as nn  #Goated import\n",
        "\n",
        "class MyModel(nn.Module): #Generally has two functions in it. -INIT and FORWARD\n",
        "#Every single pyTorch module or class has to be a subclass of nn.Module\n",
        "\n",
        "  #INIT FUNCTION - defines the structure of our model\n",
        "  def __init__(self):\n",
        "    self.hidden = nn.Linear(3,4)\n",
        "    self.output = nn.Linear(4,1)\n",
        "\n",
        "\n",
        "  #FORWARD FUNCTION - to return the model prediction\n",
        "  def forward(self, x): #x is the python input\n",
        "    hidden_output = self.hidden(x) #Input x is expected to be of shape (batch_size, 3). It does a matrix multiplication x @ Wáµ€ + b. Output shape becomes (batch_size, 4)\n",
        "    return self.output(hidden_output) #Input is the output of the first layer(here hidden). Applies second layer and reduces it into a single value. Output shape is (batch_size, 1)"
      ],
      "metadata": {
        "id": "oDE-ZY-lyd0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}